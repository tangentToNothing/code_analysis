import csv
import sys
import time
import glob
import os

# assumes you have git cloned the exploitdb in next to this repo
"""
METHOD: use inventory CSVs to extract file contents in to following format:
{
    "id": <id>,
    "code": <content of file>,
    "path": <rel/path/to/file>,
    "interesting": 0 or 1
}
"""

time0 = time.time()

FILES_EXPLOITS_INVENTORY = 'files_exploits.csv'
FILES_SHELLCODES_INVENTORY = 'files_shellcodes.csv'

OUTPUT_FILE = 'data.csv'

data_list = []

with open("../exploitdb/{}".format(FILES_EXPLOITS_INVENTORY)) as exploit_inventory:
    exploit_reader = csv.reader(exploit_inventory)
    next(exploit_reader)
    for row in exploit_reader:
        tmp_path = "../exploitdb/{}".format(row[1])
        with open(tmp_path, 'r') as exploit_code:
            _exploit = {
                "id": row[0],
                "code": exploit_code.read(),
                "path": row[1],
                "interesting": 1
            }
            data_list.append(_exploit)

with open("../exploitdb/{}".format(FILES_SHELLCODES_INVENTORY)) as shellcode_inventory:
    exploit_reader = csv.reader(shellcode_inventory)
    next(exploit_reader)
    for row in exploit_reader:
        tmp_path = "../exploitdb/{}".format(row[1])
        with open(tmp_path, 'r') as exploit_code:
            _exploit = {
                "id": row[0],
                "code": exploit_code.read(),
                "path": row[1],
                "interesting": 1
            }
            data_list.append(_exploit)

# System, etc, bin, Library, anaconda2

root_dirs = ['/System', '/etc', '/bin', '/Library', '/anaconda2', '/opt']
glob_levels = ['/*', '/*/*', '/*/*/*', '/*/*/*/*', '/*/*/*/*/*', '/*/*/*/*/*/*']

path_list = []

for directory in root_dirs:
    for glob_level in glob_levels:
        tmp_glob = directory + glob_level
        paths = [path for path in glob.glob(tmp_glob) if not os.path.isdir(path)]
        path_list.extend(paths)

id_val = 900000000000
bad_file_count = 0

for path in path_list:
    try:
        with open(path, 'r') as clean_file:
            _clean_file = {
                "id": id_val,
                "code": clean_file.read(),
                "path": path,
                "interesting": 0
            }
            id_val += 1
            data_list.append(_clean_file)
    except FileNotFoundError as e:
        bad_file_count += 1
    except:
        bad_file_count += 1

with open(OUTPUT_FILE, 'w') as data_output:
    file_writer = csv.writer(data_output)
    file_writer.writerow(['id', 'code', 'path', 'interesting'])
    for file_obj in data_list:
        file_writer.writerow([file_obj['id'], file_obj['code'], file_obj['path'], file_obj['interesting']])

time_taken = time.time() - time0

print("Completed in {} s".format(time_taken))
print("Available Data Points: {} ".format(len(data_list)))
print("Failed files: {}".format(bad_file_count))

            